{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumav\\Desktop\\Spark_Project\\youtube_de_project1-master\\data_Phoenix_migration\\venv\\lib\\site-packages\\pyspark\\context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n",
      "|first_name|last_name|salary|\n",
      "+----------+---------+------+\n",
      "|      John|      Doe| 50000|\n",
      "|      Jane|    Smith| 60000|\n",
      "|     Alice|  Johnson| 70000|\n",
      "|       Bob|    Brown| 55000|\n",
      "+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    Row(first_name=\"John\", last_name=\"Doe\", salary=50000),\n",
    "    Row(first_name=\"Jane\", last_name=\"Smith\", salary=60000),\n",
    "    Row(first_name=\"Alice\", last_name=\"Johnson\", salary=70000),\n",
    "    Row(first_name=\"Bob\", last_name=\"Brown\", salary=55000)\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the list of Row objects\n",
    "df = spark.createDataFrame(data)\n",
    "df.select(df[\"first_name\"], df[\"last_name\"], df[\"salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n",
      "|first_name|last_name|salary|\n",
      "+----------+---------+------+\n",
      "|      John|      Doe| 50000|\n",
      "|      Jane|    Smith| 60000|\n",
      "|     Alice|  Johnson| 70000|\n",
      "|       Bob|    Brown| 55000|\n",
      "+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|      John|      Doe|\n",
      "|      Jane|    Smith|\n",
      "|     Alice|  Johnson|\n",
      "|       Bob|    Brown|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"first_name\", \"last_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "result = df.groupBy(\"first_name\").agg(\n",
    "    f.count(\"*\").alias(\"count\"),\n",
    "    f.avg(\"salary\").alias(\"avg_salary\"),\n",
    "    f.max(\"salary\").alias(\"max_salary\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+----------+\n",
      "|first_name|count|avg_salary|max_salary|\n",
      "+----------+-----+----------+----------+\n",
      "|      John|    1|   50000.0|     50000|\n",
      "|      Jane|    1|   60000.0|     60000|\n",
      "|     Alice|    1|   70000.0|     70000|\n",
      "|       Bob|    1|   55000.0|     55000|\n",
      "+----------+-----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+----------+\n",
      "|first_name|last_name|salary|department|\n",
      "+----------+---------+------+----------+\n",
      "|      John|      Doe| 50000|     sales|\n",
      "|      Jane|    Smith| 60000|     sales|\n",
      "|     Alice|  Johnson| 70000|     sales|\n",
      "|       Bob|    Brown| 55000|     sales|\n",
      "+----------+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "add_column = df.withColumn(\n",
    "    \"department\",\n",
    "    lit(\"sales\")\n",
    ")\n",
    "add_column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    Row(emp_id=1, first_name=\"John\", last_name=\"Doe\", salary=50000, department_name=\"Sales\", manager_id=10, manager_name=\"Alice\"),\n",
    "    Row(emp_id=2, first_name=\"Jane\", last_name=\"Smith\", salary=60000, department_name=\"Engineering\", manager_id=20, manager_name=\"Bob\"),\n",
    "    Row(emp_id=3, first_name=\"Alice\", last_name=\"Johnson\", salary=70000, department_name=\"HR\", manager_id=30, manager_name=\"Charlie\"),\n",
    "    Row(emp_id=4, first_name=\"Bob\", last_name=\"Brown\", salary=55000, department_name=\"Sales\", manager_id=10, manager_name=\"Alice\"),\n",
    "    Row(emp_id=5, first_name=\"Eve\", last_name=\"White\", salary=65000, department_name=\"Engineering\", manager_id=20, manager_name=\"Bob\")\n",
    "]\n",
    "\n",
    "# Create DataFrame from the sample data\n",
    "df_emp = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+---------------+----------+------------+\n",
      "|emp_id|first_name|last_name|salary|department_name|manager_id|manager_name|\n",
      "+------+----------+---------+------+---------------+----------+------------+\n",
      "|     1|      John|      Doe| 50000|          Sales|        10|       Alice|\n",
      "|     2|      Jane|    Smith| 60000|    Engineering|        20|         Bob|\n",
      "|     3|     Alice|  Johnson| 70000|             HR|        30|     Charlie|\n",
      "|     4|       Bob|    Brown| 55000|          Sales|        10|       Alice|\n",
      "|     5|       Eve|    White| 65000|    Engineering|        20|         Bob|\n",
      "+------+----------+---------+------+---------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n",
      "|first_name|last_name|salary|\n",
      "+----------+---------+------+\n",
      "|      Jane|    Smith| 60000|\n",
      "|       Eve|    White| 65000|\n",
      "+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.select(\"first_name\", \"last_name\", \"salary\")\\\n",
    "    .where((df_emp[\"salary\"] > 50000) & (df_emp[\"department_name\"] == \"Engineering\"))\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+---------------+----------+\n",
      "|emp_id|first_name|last_name|salary|department_name|manager_id|\n",
      "+------+----------+---------+------+---------------+----------+\n",
      "|     1|      John|      Doe| 50000|          Sales|        10|\n",
      "|     2|      Jane|    Smith| 60000|    Engineering|        20|\n",
      "|     3|     Alice|  Johnson| 70000|             HR|        30|\n",
      "|     4|       Bob|    Brown| 55000|          Sales|        10|\n",
      "|     5|       Eve|    White| 65000|    Engineering|        20|\n",
      "+------+----------+---------+------+---------------+----------+\n",
      "\n",
      "+----------+------------+\n",
      "|manager_id|manager_name|\n",
      "+----------+------------+\n",
      "|        10|       Alice|\n",
      "|        20|         Bob|\n",
      "|        30|     Charlie|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_employees = [\n",
    "    Row(emp_id=1, first_name=\"John\", last_name=\"Doe\", salary=50000, department_name=\"Sales\", manager_id=10),\n",
    "    Row(emp_id=2, first_name=\"Jane\", last_name=\"Smith\", salary=60000, department_name=\"Engineering\", manager_id=20),\n",
    "    Row(emp_id=3, first_name=\"Alice\", last_name=\"Johnson\", salary=70000, department_name=\"HR\", manager_id=30),\n",
    "    Row(emp_id=4, first_name=\"Bob\", last_name=\"Brown\", salary=55000, department_name=\"Sales\", manager_id=10),\n",
    "    Row(emp_id=5, first_name=\"Eve\", last_name=\"White\", salary=65000, department_name=\"Engineering\", manager_id=20)\n",
    "]\n",
    "\n",
    "df_employees = spark.createDataFrame(data_employees)\n",
    "df_employees.show()\n",
    "\n",
    "data_managers = [\n",
    "    Row(manager_id=10, manager_name=\"Alice\"),\n",
    "    Row(manager_id=20, manager_name=\"Bob\"),\n",
    "    Row(manager_id=30, manager_name=\"Charlie\")\n",
    "]\n",
    "\n",
    "df_managers = spark.createDataFrame(data_managers)\n",
    "df_managers.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+---------------+----------+----------+------------+\n",
      "|emp_id|first_name|last_name|salary|department_name|manager_id|manager_id|manager_name|\n",
      "+------+----------+---------+------+---------------+----------+----------+------------+\n",
      "|     1|      John|      Doe| 50000|          Sales|        10|        10|       Alice|\n",
      "|     4|       Bob|    Brown| 55000|          Sales|        10|        10|       Alice|\n",
      "|     2|      Jane|    Smith| 60000|    Engineering|        20|        20|         Bob|\n",
      "|     5|       Eve|    White| 65000|    Engineering|        20|        20|         Bob|\n",
      "|     3|     Alice|  Johnson| 70000|             HR|        30|        30|     Charlie|\n",
      "+------+----------+---------+------+---------------+----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined = df_employees.join(df_managers, df_employees[\"manager_id\"] == df_managers[\"manager_id\"], \"inner\")\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+---------------+----------+----------+------------+\n",
      "|emp_id|first_name|last_name|salary|department_name|manager_id|manager_id|manager_name|\n",
      "+------+----------+---------+------+---------------+----------+----------+------------+\n",
      "|     1|      John|      Doe| 50000|          Sales|        10|        10|       Alice|\n",
      "|     2|      Jane|    Smith| 60000|    Engineering|        20|        20|         Bob|\n",
      "|     3|     Alice|  Johnson| 70000|             HR|        30|        30|     Charlie|\n",
      "|     4|       Bob|    Brown| 55000|          Sales|        10|        10|       Alice|\n",
      "|     5|       Eve|    White| 65000|    Engineering|        20|        20|         Bob|\n",
      "+------+----------+---------+------+---------------+----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined = df_employees.join(df_managers, df_employees[\"manager_id\"] == df_managers[\"manager_id\"], \"left\")\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+\n",
      "|department_name|employee_count|\n",
      "+---------------+--------------+\n",
      "|          Sales|             2|\n",
      "|    Engineering|             2|\n",
      "|             HR|             1|\n",
      "+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "department_count_df = df_employees.groupBy(\"department_name\").agg(\n",
    "    F.count(\"*\").alias(\"employee_count\")\n",
    ")\n",
    "department_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "data = [\n",
    "    (1, \"John\", \"Doe\", 50000),\n",
    "    (2, \"Jane\", \"Smith\", 60000),\n",
    "    (3, \"Alice\", \"Johnson\", 70000),\n",
    "    (4, \"Bob\", \"Brown\", 55000),\n",
    "    (5, \"Eve\", \"White\", 65000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+\n",
      "|emp_id|first_name|last_name|salary|\n",
      "+------+----------+---------+------+\n",
      "|     1|      John|      Doe| 50000|\n",
      "|     2|      Jane|    Smith| 60000|\n",
      "|     3|     Alice|  Johnson| 70000|\n",
      "|     4|       Bob|    Brown| 55000|\n",
      "|     5|       Eve|    White| 65000|\n",
      "+------+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employees = spark.createDataFrame(data, [\"emp_id\", \"first_name\", \"last_name\", \"salary\"])\n",
    "df_employees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n",
      "|first_name|last_name|salary|\n",
      "+----------+---------+------+\n",
      "|       Eve|    White| 65000|\n",
      "+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_spec = Window.orderBy(F.col(\"salary\").desc())\n",
    "\n",
    "df_with_rank = df_employees.withColumn(\"rank\", F.dense_rank().over(window_spec))\n",
    "second_highest = df_with_rank.filter(df_with_rank[\"rank\"] == 2).select(\"first_name\", \"last_name\", \"salary\")\n",
    "\n",
    "second_highest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+---------------+----------+------------+\n",
      "|emp_id|first_name|last_name|salary|department_name|manager_id|manager_name|\n",
      "+------+----------+---------+------+---------------+----------+------------+\n",
      "|     1|      John|      Doe| 50000|          Sales|        10|       Alice|\n",
      "|     2|      Jane|    Smith| 60000|    Engineering|        20|         Bob|\n",
      "|     3|     Alice|  Johnson| 70000|             HR|        30|     Charlie|\n",
      "|     4|       Bob|    Brown| 55000|          Sales|        10|       Alice|\n",
      "|     5|       Eve|    White| 65000|    Engineering|        20|         Bob|\n",
      "+------+----------+---------+------+---------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+---------------+----+\n",
      "|first_name|last_name|salary|department_name|rank|\n",
      "+----------+---------+------+---------------+----+\n",
      "|      Jane|    Smith| 60000|    Engineering|   1|\n",
      "|       Eve|    White| 65000|    Engineering|   2|\n",
      "|     Alice|  Johnson| 70000|             HR|   1|\n",
      "|      John|      Doe| 50000|          Sales|   1|\n",
      "|       Bob|    Brown| 55000|          Sales|   2|\n",
      "+----------+---------+------+---------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_row = Window.partitionBy(\"department_name\").orderBy(\"salary\")\n",
    "\n",
    "df_row_num = df_employees.withColumn(\"rank\", F.row_number().over(window_row))\n",
    "result_df = df_row_num.select(\"first_name\", \"last_name\", \"salary\",\"department_name\", \"rank\")\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+---------------+----------+------------+---------------+\n",
      "|emp_id|first_name|last_name|salary|department_name|manager_id|manager_name|salary_category|\n",
      "+------+----------+---------+------+---------------+----------+------------+---------------+\n",
      "|     1|      John|      Doe| 50000|          Sales|        10|       Alice|           High|\n",
      "|     2|      Jane|    Smith| 60000|    Engineering|        20|         Bob|           High|\n",
      "|     3|     Alice|  Johnson| 70000|             HR|        30|     Charlie|           High|\n",
      "|     4|       Bob|    Brown| 55000|          Sales|        10|       Alice|           High|\n",
      "|     5|       Eve|    White| 65000|    Engineering|        20|         Bob|           High|\n",
      "+------+----------+---------+------+---------------+----------+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_case_when = df_employees.withColumn(\n",
    "            \"salary_category\", \n",
    "            F.when(df_employees[\"salary\"] > 10000, \"High\")\n",
    "             .when(df_employees[\"salary\"] == 70000,  \"low\")\n",
    "             .otherwise(\"heavy\")\n",
    "            )\n",
    "df_case_when.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Mahesh:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x6d63cb0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|formatted_date|\n",
      "+--------------+\n",
      "|    2025-01-22|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(1).select(F.date_format(F.current_date(), \"yyyy-MM-dd\").alias(\"formatted_date\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|employee_name|manager_name|\n",
      "+-------------+------------+\n",
      "|        Alice|     Charlie|\n",
      "|          Bob|     Charlie|\n",
      "|      Charlie|        null|\n",
      "|        David|         Bob|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data = [\n",
    "    (1, \"Alice\", 3),\n",
    "    (2, \"Bob\", 3),\n",
    "    (3, \"Charlie\", None),\n",
    "    (4, \"David\", 2)\n",
    "]\n",
    "\n",
    "# Define schema\n",
    "columns = [\"employee_id\", \"employee_name\", \"manager_id\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df_employees = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Perform self-join\n",
    "# We join df_employees with itself using aliases to differentiate between the employee and manager sides\n",
    "df_with_manager = df_employees.alias(\"emp\").join(df_employees.alias(\"mgr\"), col(\"emp.manager_id\") == col(\"mgr.employee_id\"),\"left\" )\n",
    "\n",
    "# Select relevant columns (e.g., employee name and manager name)\n",
    "df_with_manager = df_with_manager.select(\n",
    "    col(\"emp.employee_name\").alias(\"employee_name\"),\n",
    "    col(\"mgr.employee_name\").alias(\"manager_name\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "df_with_manager.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

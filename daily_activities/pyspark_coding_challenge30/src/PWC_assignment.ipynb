{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Which of the following is NOT a valid Spark transformation?        \n",
    "    *   a) `map`        \n",
    "    *   b) `filter`        \n",
    "    *   c) `reduceByKey`        \n",
    "    *   d) `collect`        \n",
    "    *   e) `flatMap` \n",
    "\n",
    "Answer - d - collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  What is the primary purpose of the Spark Catalyst Optimizer?        \n",
    "    *   a) To manage cluster resources.        \n",
    "    *   b) To optimize query execution plans.        \n",
    "    *   c) To handle data serialization and deserialization.        \n",
    "    *   d) To provide a user-friendly web interface.        \n",
    "    *   e) To load data     \n",
    "\n",
    "Answer - b - To optimize query execution plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  What is the difference between `persist()` and `cache()` in PySpark?        \n",
    "    *   a) `persist()` allows you to specify a storage level, while `cache()` always uses `MEMORY_AND_DISK`.        \n",
    "    *   b) `cache()` allows you to specify a storage level, while `persist()` always uses `MEMORY_ONLY`.        \n",
    "    *   c) `persist()` allows you to specify a storage level, while `cache()` always uses `MEMORY_ONLY`.        \n",
    "    *   d) There is no functional difference; they are synonyms.        \n",
    "    *   e) `persist()` is used for RDD while `cache()` is for DataFrame \n",
    "\n",
    "Answer - a - `persist()` allows you to specify a storage level, while `cache()` always uses `MEMORY_AND_DISK`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  What does the repartition() transformation do?        \n",
    "    *   a) Filters rows based on a condition.        \n",
    "    *   b) Changes the number of partitions in an RDD or DataFrame, potentially causing a full shuffle.        \n",
    "    *   c) Groups data by a key.        \n",
    "    *   d) Sorts data within each partition.        \n",
    "    *   e) Renames a column.   \n",
    "\n",
    "Answer - b - Changes the number of partitions in an RDD or DataFrame, potentially causing a full shuffle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  Which of the following is the most efficient way to perform a join between two large DataFrames in Spark?        \n",
    "    *   a)  Using a cross join followed by a filter.        \n",
    "    *   b)  Using a broadcast join if one DataFrame is significantly smaller than the other.        \n",
    "    *   c)  Using a Cartesian product.        \n",
    "    *   d)  Always using a sort-merge join, regardless of DataFrame size.        \n",
    "    *   e)  Converting to RDD and using groupByKey   \n",
    "\n",
    "Answer - b - Using a broadcast join if one DataFrame is significantly smaller than the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark Code Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumav\\Desktop\\Spark_Project\\youtube_de_project1-master\\data_Phoenix_migration\\venv\\lib\\site-packages\\pyspark\\context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PWC Assignment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Mahesh:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PWC Assignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x6689bf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+----------------+-------------+--------------------+-------------------+--------------+-----------+\n",
      "|         customer_id|    customer_name|      customer_email| customer_join_date|          product_id|       product_name|product_category|product_price|            order_id|         order_date|order_quantity|order_total|\n",
      "+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+----------------+-------------+--------------------+-------------------+--------------+-----------+\n",
      "|00b4dd52-2e04-4d5...|      Jason Brown|daniellewilson@ex...|2020-07-08 04:57:44|42f5a305-f9ba-4da...|External Hard Drive|     Peripherals|          128|a92b0353-a064-491...|2024-08-27 16:51:18|             3|        384|\n",
      "|6c437811-1a00-420...|   David Sandoval|kgriffin@example.com|2020-03-19 09:37:53|5d925294-5b72-484...|            Monitor|           Audio|          335|61eff311-c912-4a2...|2023-12-09 21:32:11|             2|        670|\n",
      "|8b9e7b50-c3a4-428...|   Maria Galloway|annahamilton@exam...|2024-03-15 07:50:55|d8f4aee1-68a6-4f1...|    USB Flash Drive|       Wearables|          499|76aeb577-2be6-417...|2025-02-18 10:47:50|             3|       1497|\n",
      "|17cb0f89-361e-499...|    Brian Maxwell|christine35@examp...|2020-09-15 00:57:13|2f82bd7c-8404-406...|     Gaming Console|     Photography|         1418|5a5150a6-43ae-42c...|2024-07-23 02:40:07|             3|       4254|\n",
      "|d100b560-7336-426...|Michele Mathis MD| gdudley@example.org|2022-10-13 12:07:12|7c576f32-db24-458...|         Smartphone|     Electronics|          434|e7bbdb5f-1314-40a...|2023-12-03 16:13:27|             1|        434|\n",
      "|b2669995-b0d0-471...|         Amy Dunn|allison33@example...|2024-09-30 08:36:26|c1ebc413-3be4-43c...|    Fitness Tracker|     Accessories|          190|4c48bf20-b520-4a3...|2025-02-07 10:22:43|             5|        950|\n",
      "|ab8454d2-63dc-405...|      Sheri Drake|lvalencia@example...|2021-01-06 03:55:21|f9309ebe-ab43-4af...|            Scanner|     Peripherals|         1683|572f0dd1-1960-412...|2024-02-15 19:24:34|             1|       1683|\n",
      "|ded35ff4-5f5f-494...|       Todd Young|arianabennett@exa...|2022-12-16 03:26:47|a66b90cb-689d-42b...|            Charger|      Networking|          702|e16967e4-e2c9-4b3...|2024-05-03 21:12:38|             5|       3510|\n",
      "|7cc164f2-673a-4ee...|  Alexander Poole| bmooney@example.net|2021-03-16 12:01:46|d103bbd0-3441-413...|         Smartphone|      Networking|          488|61f19963-54e5-43b...|2022-01-31 04:05:02|             3|       1464|\n",
      "|848d7437-788d-45e...|    Laura Goodwin|  adam32@example.net|2021-02-12 23:27:20|0ebba55d-8a42-4d3...|    USB Flash Drive|     Accessories|          331|82bcbcb4-c47a-46f...|2021-07-24 15:42:13|             1|        331|\n",
      "|5a2df26a-c79b-46b...|    Edward Dennis|  chad26@example.com|2021-06-10 05:03:19|519b895e-3750-47d...|      Computer Case|     Accessories|         1890|9fd8211b-1ce2-48b...|2022-02-24 09:20:50|             5|       9450|\n",
      "|b3efa486-7e84-465...|        Meghan Yu|valdezkatie@examp...|2020-12-07 01:26:59|2d5d19f1-af40-4fc...|         VR Headset|     Accessories|         1514|e68bba54-c3f5-411...|2024-09-16 01:04:46|             5|       7570|\n",
      "|98b63428-c1d2-494...|    Bradley Ayers|youngmichael@exam...|2023-04-12 23:29:04|fc56dc81-eda5-4ed...|             Tablet|       Wearables|          651|a3e3463f-2bd7-4fd...|2023-06-13 21:09:33|             3|       1953|\n",
      "|bdeba44e-0ca5-491...|    Antonio Burke|  vyoung@example.com|2022-05-09 06:29:14|003e06b4-82d0-439...|            Charger|      Networking|           67|9c650773-a2bd-483...|2022-11-18 22:34:32|             3|        201|\n",
      "|095596f5-f522-418...|  Cassie Williams| xmartin@example.net|2021-10-27 06:53:27|17ea46f1-403e-4ef...|        Motherboard|       Wearables|          384|4d3b6bd9-beba-41e...|2023-11-01 04:58:39|             2|        768|\n",
      "|3b19596a-6571-4fd...|     Samuel Myers|garcianicole@exam...|2022-03-28 03:16:14|47da5015-3cad-44b...|External Hard Drive|     Peripherals|           70|57673b1a-4a86-4ca...|2024-11-03 07:27:46|             5|        350|\n",
      "|ffbe6e62-35b1-42f...|  Anthony Merritt|ymartinez@example...|2020-04-29 13:32:42|a843ade8-5dd0-4af...|  Bluetooth Speaker|       Wearables|         1078|db6ee6ef-4c9f-4f0...|2020-08-15 04:24:11|             1|       1078|\n",
      "|d02d9392-4709-4f3...|  Theresa Vasquez|  eric94@example.org|2021-04-05 13:51:54|e3daabe1-2d6a-492...|        Motherboard|     Electronics|         1270|f93dab7b-893b-49a...|2024-12-10 12:47:46|             3|       3810|\n",
      "|11b214f5-2f3b-49e...|       Anna Mejia|hayesjames@exampl...|2024-04-14 09:21:06|f6ab139d-98bb-4e6...|             Laptop|   PC Components|         1661|043a540f-d677-4dd...|2024-04-15 10:36:48|             2|       3322|\n",
      "|600576e9-2379-488...| Dorothy Johnston|darrylbanks@examp...|2022-11-30 07:14:56|9b19bb0e-4dbe-4bc...|         Smartwatch|           Audio|          347|e6cd83e4-28b6-4f4...|2024-04-28 03:29:54|             5|       1735|\n",
      "+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+----------------+-------------+--------------------+-------------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_orders = spark.read.format('csv').option('header', 'true')\\\n",
    "                                         .option('inferSchema', 'true')\\\n",
    "                                         .load(\"C:\\\\Users\\\\kumav\\\\Downloads\\\\customer_orders.csv\")\n",
    "customer_orders.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.  Find the total number of orders for each product category.  Display the category and the order count, sorted by order count in descending order.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+\n",
      "|product_category|Total_orders|\n",
      "+----------------+------------+\n",
      "|       Wearables|         379|\n",
      "|   PC Components|         372|\n",
      "|     Accessories|         364|\n",
      "|     Peripherals|         356|\n",
      "|       Computers|         348|\n",
      "|     Photography|         341|\n",
      "|     Electronics|         341|\n",
      "|           Audio|         336|\n",
      "|      Networking|         335|\n",
      "|          Gaming|         328|\n",
      "+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_6 = customer_orders.groupBy(F.col(\"product_category\"))\\\n",
    "                    .agg(F.count(\"order_id\").alias(\"Total_orders\"))\\\n",
    "                    .orderBy(F.desc(F.col(\"Total_orders\")))\n",
    "df_6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  Calculate the average order total for each customer. Display the customer ID, customer name, and their average order total, rounded to two decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+---------------+\n",
      "|         customer_id|   customer_name|avg_order_total|\n",
      "+--------------------+----------------+---------------+\n",
      "|e32a57df-aec7-4d1...|Michael Mitchell|          654.0|\n",
      "|535cc9c9-d3d7-423...|Jeanette Perkins|         2517.0|\n",
      "|c3648934-6ed9-4d9...| Julie Rodriguez|          333.0|\n",
      "|1dc0515e-e826-4fe...|   Raymond Price|         1973.0|\n",
      "|2978a6d1-ba2d-4ca...|    Steven Davis|          510.0|\n",
      "|d10383c9-7131-435...|     David Black|         1234.0|\n",
      "|82d848b5-0d24-4b9...|    Tyler Church|         5658.0|\n",
      "|c62ef076-77e9-4d7...|     Joe Goodman|         1928.0|\n",
      "|1ba91b27-c7c2-445...|  Valerie Warren|         1276.0|\n",
      "|ff0a9b17-bb91-474...|  Daniel Carlson|          404.0|\n",
      "|1b2264b9-ba9e-4b8...|     Daniel Love|         1041.0|\n",
      "|517225cf-a73a-427...|Jasmine Robinson|         2390.0|\n",
      "|1df6bd36-8e07-4ff...| Mackenzie Evans|         1902.0|\n",
      "|13daa5e0-85dc-484...| Lawrence Snyder|         4516.0|\n",
      "|79049f98-a54a-4b7...|  Jeffery Miller|         2594.0|\n",
      "|7908f2a8-d2c3-496...|  Sabrina Cooper|         5608.0|\n",
      "|9821ec09-3c1a-433...|     Nicole Holt|         1452.0|\n",
      "|4e2bf4fd-21a2-4de...|   Jeffrey Baker|         1497.0|\n",
      "|fc1438aa-6bfb-487...| Charles Hawkins|          983.0|\n",
      "|9fc2f8d5-1903-4c7...|     Zachary May|          711.0|\n",
      "+--------------------+----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_7 = customer_orders.groupBy(F.col(\"customer_id\"), F.col(\"customer_name\"))\\\n",
    "                      .agg(F.round(F.avg(F.col(\"order_total\")), 2).alias(\"avg_order_total\"))\n",
    "\n",
    "df_7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- customer_email: string (nullable = true)\n",
      " |-- customer_join_date: timestamp (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- product_price: integer (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_quantity: integer (nullable = true)\n",
      " |-- order_total: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_orders.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.  Find the customers who joined in the last year (from today) and have placed more than 3 orders. Display customer ID, join date, and total order count.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_last_years = customer_orders.filter(F.col(\"customer_join_date\") >= F.date_sub(F.current_date(), 365))\n",
    "customers_last_years.count()\n",
    "# recent_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_orders_count = customers_last_years.groupBy(\"customer_id\") \\\n",
    "    .agg(F.count(\"order_id\").alias(\"total_orders\"))\n",
    "\n",
    "customer_orders_count.count()\n",
    "# customer_orders_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|customer_id|total_orders|\n",
      "+-----------+------------+\n",
      "+-----------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eligible_customers = customer_orders_count.filter(F.col(\"total_orders\") > 3)\n",
    "eligible_customers.show()\n",
    "eligible_customers.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.  What is the most popular product (highest total quantity ordered)? Display the product name and total quantity ordered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e12efc92231a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mproduct_quantity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomer_orders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"product_name\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m                                   \u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"order_quantity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"total_quantity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproduct_quantity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"total_quantity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_9\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "product_quantity = customer_orders.groupBy(\"product_name\") \\\n",
    "                                  .agg(sum(\"order_quantity\").alias(\"total_quantity\"))\n",
    "\n",
    "df_9 = product_quantity.orderBy(F.col(\"total_quantity\").desc()).limit(1)\n",
    "df_9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create a new column called `order_year_month` that represents the year and month of each order in the format \"YYYY-MM\".        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = customer_orders.withColumn(\"order_year_month\", F.date_format(\"order_date\", \"yyyy-MM\"))\n",
    "df_10.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
